<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>MVG-多视图几何（一） | KMnO4的行云小扎</title><meta name="keywords" content="计算机视觉,SFM"><meta name="author" content="KMnO4"><meta name="copyright" content="KMnO4"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="多视图几何(Multi view Geometry)中广泛使用到矩阵运算，因此在开始MVG之旅前，先将MVG中重点使用的线代表示介绍一下。这一章中主要涉及到向量空间的表示以及基本的矩阵运算，包括像内积与叉积。接着有适用于刚体运动的李群和李代数的讲解，最后涉及到特征值，特征向量，以及通过SVD分解求解方程的知识。 Chapter 1 Mathematical Background Linear Al">
<meta property="og:type" content="article">
<meta property="og:title" content="MVG-多视图几何（一）">
<meta property="og:url" content="https://wastoon.github.io/2022/02/21/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95%EF%BC%88%E4%B8%80%EF%BC%89/index.html">
<meta property="og:site_name" content="KMnO4的行云小扎">
<meta property="og:description" content="多视图几何(Multi view Geometry)中广泛使用到矩阵运算，因此在开始MVG之旅前，先将MVG中重点使用的线代表示介绍一下。这一章中主要涉及到向量空间的表示以及基本的矩阵运算，包括像内积与叉积。接着有适用于刚体运动的李群和李代数的讲解，最后涉及到特征值，特征向量，以及通过SVD分解求解方程的知识。 Chapter 1 Mathematical Background Linear Al">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://wastoon.github.io/img/MVG-1-cover.png">
<meta property="article:published_time" content="2022-02-21T10:48:34.000Z">
<meta property="article:modified_time" content="2022-02-23T11:31:31.695Z">
<meta property="article:author" content="KMnO4">
<meta property="article:tag" content="计算机视觉">
<meta property="article:tag" content="SFM">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://wastoon.github.io/img/MVG-1-cover.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://wastoon.github.io/2022/02/21/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95%EF%BC%88%E4%B8%80%EF%BC%89/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'MVG-多视图几何（一）',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-02-23 19:31:31'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-butterfly-clock/lib/clock.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/l-lin/font-awesome-animation/dist/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.min.css" media="defer" onload="this.media='all'"><script async src="https://cdn.jsdelivr.net/npm/hexo-butterfly-tag-plugins-plus@latest/lib/carousel-touch.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-filter-gitcalendar/lib/gitcalendar.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/icon.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">10</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">8</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 网站统计</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 自留地</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 吉他谱</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 嗑盐&amp;摸鱼</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 文献</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 经典开源项目</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 个人项目</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/MVG-1-cover.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">KMnO4的行云小扎</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 网站统计</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 自留地</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 吉他谱</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 嗑盐&amp;摸鱼</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 文献</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 经典开源项目</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 个人项目</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">MVG-多视图几何（一）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-02-21T10:48:34.000Z" title="发表于 2022-02-21 18:48:34">2022-02-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-02-23T11:31:31.695Z" title="更新于 2022-02-23 19:31:31">2022-02-23</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/SFM/">SFM</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">4.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>27分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="MVG-多视图几何（一）"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>多视图几何(Multi view Geometry)中广泛使用到矩阵运算，因此在开始MVG之旅前，先将MVG中重点使用的线代表示介绍一下。这一章中主要涉及到向量空间的表示以及基本的矩阵运算，包括像内积与叉积。接着有适用于刚体运动的李群和李代数的讲解，最后涉及到特征值，特征向量，以及通过SVD分解求解方程的知识。</p>
<h1 id="Chapter-1-Mathematical-Background-Linear-Algebra"><a href="#Chapter-1-Mathematical-Background-Linear-Algebra" class="headerlink" title="Chapter 1 Mathematical Background Linear Algebra"></a>Chapter 1 Mathematical Background Linear Algebra</h1><p>##1.1 Vector Spaces</p>
<p>A set $V$ is called a <code>linear space</code> or  a <code>vector space over the field</code> $\mathbb{R}$ if it is closed under vector summation<br>$$+:V\times V \rightarrow V$$<br>and  under scalar multiplication<br>$$\dot : \mathbb{R} \times V \rightarrow V, $$</p>
<p>i.e. $\alpha v_1 + \beta v_2 \in V \forall v_1, v_2 \in V, \forall \alpha, \beta \in \mathbb{R}$. With respect to addition $(+)$ it forms a commutative group (existence of neutral element 0, inverse element $-v$). Scalar multiplication and addition respect the distributive law:<br>$$(\alpha + \beta)v &#x3D; \alpha v + \beta v \quad \alpha (v+u)&#x3D;\alpha v + \alpha u.$$<br>Example: $V&#x3D;\mathbb{R}^n, v &#x3D; (x_1, x_2, …, x_n)^T$.</p>
<p>A subset $W\subset V$ of a vector space $V$ is called <code>subspace</code> if $0 \in W$ and $W $ is closed under $+$ and $\cdot$ (for all $\alpha \in \mathbb{R}$)</p>
<p>##1.2 Linear Independence and Basis<br>The spanned subspace of a set of vectors $S&#x3D;{v_1, v_2, …, v_k} \subset V$ is the subspace formed by all linear combination s of these vectors:</p>
<p>$$span(S) &#x3D; {v\in V | v &#x3D; \sum_{i&#x3D;1}^k \alpha_i v_i}$$<br>The set $S$ is called <code>linear independent</code> if:<br>$$\sum_{i&#x3D;1}^k \alpha_i v_i&#x3D;0  \Rightarrow \alpha_i&#x3D;0 \forall i.$$</p>
<p>$$<br>Assume: \<br>\sum_{i&#x3D;1}^k \alpha_i v_i &#x3D;0 \quad \land \alpha_i \neq 0 \<br>\Rightarrow v_j &#x3D; -\frac{1}{\alpha_j}\sum_{i&#x3D;1, i\neq j}^k \alpha_i v_i<br>$$</p>
<p>in other word, if none of the vectors can be expressed as a linear combination of the remaining vectors. Otherwise the set is called <code>linear dependent</code>.</p>
<p>A set of vectors $B&#x3D;{v_1, v_2, …,v_n}$ is called a <code>basis of</code> $V$ if it is linearly independent and if it spans the vector space $V$. A basis is a maximal set of linearly independent vectors.</p>
<p>##1.3 Properties of a Basis<br>Let $B$ and $B’$ be two bases of a linear space $V$.</p>
<ul>
<li>$B$ and $B’$ contain the same number of vectors. This number $n$ is called <code>dimension of the space</code> $V$.</li>
<li>Any vector $v\in V$ can be uniquely expressed as a linear combination of the basis vectors in $B&#x3D;{b_1, b_2, …, b_n}:$<br>$$<br>v &#x3D; \sum_{i&#x3D;1}^n \alpha_i b_i<br>$$</li>
<li>In particular, all vectors of $B$ can be expressed as linear combinations of vectors of another basis $b_j’\in B’$:<br>$$<br>b_i’ &#x3D; \sum_{j&#x3D;1}^n \alpha_{ji}b_j<br>$$</li>
</ul>
<p>The coefficients $\alpha_{ji}$ for this <code>basis transform</code> can be combined in a matrix $A$. Setting $B&#x3D;(b_1, b_2, …, b_n)$ and $B’&#x3D;(b_1’, b_2’, .., b_n’)$ as the matrices of basis vectors, we can write: $B’&#x3D;BA \Leftrightarrow B&#x3D; B’A^{-1}$.</p>
<p>##1.4 Inner Product<br>On a vector space one can define an <code>inner product (dot product)</code>, dt: Skalarproduct $\neq$ skalare Multiplication:<br>$$<br>(\cdot, \cdot): V \times V \rightarrow \mathbb{R}<br>$$<br>which is defined by three properties:</p>
<ul>
<li>$(u, \alpha v + \beta w) &#x3D; \alpha (u,v) + \beta (u, w) \quad (linear)$</li>
<li>$(u, v) &#x3D; (v, u) \quad (symmetric)$</li>
<li>$(v, v) \geq 0$ and  $(v, v)&#x3D;0 \Leftrightarrow v&#x3D;0\quad (positive \ definite)$</li>
</ul>
<p>The scalar product induces a <code>norm</code>:<br>$$<br>|\cdot|: V \rightarrow \mathbb{R}, \quad |v| &#x3D; \sqrt{(v, v)}<br>$$<br>and a <code>metric</code>:<br>$$<br>d: V\times V \rightarrow \mathbb{R}, \quad d(v, w) &#x3D; |v-w| &#x3D; \sqrt{(v-w, v-w)}<br>$$<br>for measuring lengths and distances, making $V$ a <code>metrin space</code>. Since the metric is induced by a scalar produt $V$ is called a <code>Hilbert space</code>.</p>
<h2 id="1-5-Canocial-and-Induces-Inner-Product"><a href="#1-5-Canocial-and-Induces-Inner-Product" class="headerlink" title="1.5 Canocial and Induces Inner Product"></a>1.5 Canocial and Induces Inner Product</h2><p>On $V&#x3D;\mathbb{R}^n$, one can define the canoncial inner product for the canoncial basis $B&#x3D;I_n$ as:<br>$$<br>(x, y) &#x3D; x^T y &#x3D; \sum_{i&#x3D;1}^n x_iy_i,<br>$$<br>which induces the standard $L_2$ norm or Euclidean norm:<br>$$<br>|x|_2 &#x3D; \sqrt{x^Tx} &#x3D; \sqrt{x_1^2+ … + x_n^2}.<br>$$</p>
<p>with a basis transform $A$ to the new basis $B’$ given by $I &#x3D; B’A^{-1}$ the canoncial product in the new coordinates $x’, y’$ is given by :<br>$$<br>(x ,y) &#x3D; x^Ty &#x3D; (Ax’)^T(Ay’) &#x3D; x’^TA^TAy’\equiv (x’, y’)_{A^TA}<br>$$</p>
<p>The latter product is called the <code>induced inner product</code> fron the matrix $A$.</p>
<p>Two vectors $v$ and $w$ are <code>orthogonal</code> iff $(v, w)&#x3D;0$.</p>
<h2 id="1-6-Kronecker-Product-and-Stack-of-a-Matrix"><a href="#1-6-Kronecker-Product-and-Stack-of-a-Matrix" class="headerlink" title="1.6 Kronecker Product and Stack of a Matrix"></a>1.6 Kronecker Product and Stack of a Matrix</h2><p>Given two matrices $A\in \mathbb{R}^{m \times n}$ and $B\in \mathbb{R}^{k\times l}$, one can define their <code>Kronecker product</code> $A\otimes B$ by:<br>$$<br>A\otimes B \equiv \left(<br>\begin{matrix}<br> a_{11}B        &amp; \cdots &amp; a_{1n}B      \\<br> \vdots  &amp; \ddots &amp; \vdots \\<br>a_{m1}B        &amp; \cdots &amp; a_{mn}B      \\<br>\end{matrix}<br>\right) \in \mathbb{R}^{mk\times nl}.<br>$$</p>
<p>In matlab ths can be implemented by <code>C=kron(A, B)</code>.</p>
<p>Given a matrix $A\in \mathbb{R}^{m\times n}$, its <code>stack</code> $A^s$ is obtained by staking its $n$ column vectors $a_1, …, a_n \in \mathbb{R}^m$:<br>$$<br>A^s \equiv \left(<br>    \begin{matrix}<br>    a_1\\<br>    \vdots \\<br>    a_n<br>    \end{matrix}<br>    \right) \in \mathbb{R}^{mn}.<br>$$</p>
<p>These notations allow to rewrite algebraic xpressions, for example:<br>$$<br>u^TAv &#x3D; (v\otimes u)^T A^s<br>$$</p>
<h2 id="1-7-Linear-Transformation-and-Matrices"><a href="#1-7-Linear-Transformation-and-Matrices" class="headerlink" title="1.7 Linear Transformation and Matrices"></a>1.7 Linear Transformation and Matrices</h2><p>Linear algebra studies the properties of linear transformations between linear spaces. Since these can be represented by matrices, linear algebra studies the properties of matrices. A <code>linear transformation</code> $L$ between two linear spaces $V$ and $W$ is a map $L: V\rightarrow W$ such that:</p>
<ul>
<li>$L(x+y) &#x3D; L(x) + L(y) \quad \forall x, y \in V$</li>
<li>$L(\alpha x) &#x3D; \alpha L(x) \quad \forall x \in V, \alpha \in \mathbb{R}$.</li>
</ul>
<p>Due to the linearity, the action of $L$ on the space $V$ is uniquely defined its action on the basis vectors of $V$. In the canoncial basis ${e_1, …,e_n}$ we have:<br>$$<br>L(x) &#x3D; Ax \quad \forall x\in V,<br>$$<br>where<br>$$<br>A &#x3D; (L(e_1), …, L(e_n)) \quad \in \mathbb{R}^{m\times n}.<br>$$</p>
<p>The set of all real $m\times n$ matrices is denoted by $M(m, n)$. In the case that $m&#x3D;n$, the set $M(m, n)\equiv M(n)$ forms a <code>ring</code> over the field $\mathbb{R}$, i.e. it is closed under matrix multiplication and summation.</p>
<h2 id="1-8-The-linear-Groups-GL-n-and-SL-n"><a href="#1-8-The-linear-Groups-GL-n-and-SL-n" class="headerlink" title="1.8 The linear Groups $GL(n)$ and $SL(n)$"></a>1.8 The linear Groups $GL(n)$ and $SL(n)$</h2><p>There exist certain sets of linear transformstions which form a group.</p>
<p>A <code>group</code> is a set $G$ with an operation $\circ: G \times G \rightarrow G$ such that :</p>
<ul>
<li>$g_1 \circ g_2 \in G \quad \forall g_1, g_2 \in G $ (closed).</li>
<li>$(g_1 \circ g_2) \circ g_3 &#x3D; g_1 \circ(g_2 \circ g_3) \forall g_1 ,g_2 ,g_3 \in G$ (assoc.)</li>
<li>$\exists e\in G: e\circ g&#x3D;g\circ e &#x3D; g \quad \forall g\in G$ (neutral),</li>
<li>$\exists g^{-1} \in G: g\circ g^{-1} &#x3D; g^{-1}\circ g &#x3D; e \quad \forall g \in G$ (inverse).</li>
</ul>
<p>Example: All invertible (non-singular) real $n\times n$-matrices form a group with respect to matrix multiplication. This group is called the <code>general linear froup</code> $GL(n)$. It consists of all $A\in M(n)$ for which<br>$$<br>det(A) \neq 0<br>$$</p>
<p>All matrices $A\in GL(n)$ for which $det(A)&#x3D;1$ form a group called the $special linear group SL(n)$. The inverse of $A$ is also in the group, as $det(A^{-1})&#x3D;det(A)^{-1}$.</p>
<h2 id="1-9-Matrix-Representation-of-Groups"><a href="#1-9-Matrix-Representation-of-Groups" class="headerlink" title="1.9 Matrix Representation of Groups"></a>1.9 Matrix Representation of Groups</h2><p>A group $G$ has a <code>matrix representation</code> (dt: Darstellung) or can be realized as a matrix froup if there exists an injective transformation:<br>$$<br>R: G\rightarrow GL(n)<br>$$<br>which <code>preserves the group structure</code> of $G$ that is inverse and composition are preserved by the map:<br>$$<br>R(e)&#x3D;I_{m\times n}, R(g\circ h) &#x3D; R(g)R(h) \quad \forall g, h\in G<br>$$</p>
<p>Such a map $R$ is called a <code>grop homomorphism (dt: Homomorphismus)</code>.</p>
<p>The idea of matrix representations of a group is that they allow to analyze more abstract groups by looking at the properties of the respective matrix group. Example: The rotations of an object form a group, as there exists a neutral element (no rotation) and an inverse (the inverse rotation) and any concatenation of rotations is again a rotation (around a different axis). Studing the properties of the rotation group is easier if rotations are represented by respective matrices. </p>
<h2 id="1-10-The-Affine-Group-A-n"><a href="#1-10-The-Affine-Group-A-n" class="headerlink" title="1.10 The Affine Group $A(n)$"></a>1.10 The Affine Group $A(n)$</h2><p>An afine transformation $L: \mathbb{R}^n \rightarrow \mathbb{R}^n$ is defined by a matrix $A\in GL(n)$ and a vector $b \in \mathbb{R}^n$ such that:<br>$$<br>L(x)&#x3D;Ax+b<br>$$</p>
<p>The set of all such affine transformations is called the <code>affine group of dimension n</code>, denoted by $A(n)$. </p>
<p>$L$ defined above is not a linear map unless $b&#x3D;0$. By introducing <code>homogeneous coordinates</code> to represent $x\in \mathbb{R}^n$ by $\left(\begin{matrix}x \ 1\end{matrix}\right) \in \mathbb{R}^{n+1}$, $L$ becomes a linear mapping from<br>$$<br>L:\mathbb{R}^{n+1}\rightarrow \mathbb{R}^{n+1}; \quad \left(<br>    \begin{matrix}<br>    x\\   1<br>    \end{matrix}<br>    \right) \rightarrow \left(<br>    \begin{matrix}<br>    A \ &amp;b  \\<br>    0\ &amp;1<br>    \end{matrix}<br>    \right)\left(<br>    \begin{matrix}<br>    x \\  1<br>    \end{matrix}<br>    \right).<br>$$</p>
<p>A matrix $\left(<br>    \begin{matrix}<br>    A \ &amp;b\\<br>    0\ &amp;1<br>    \end{matrix}<br>    \right)$ with $A\in GL(n)$ and $b\in \mathbb{R}^n$ is called an <code>affine matrix</code>. It is an element of $GL(n+1)$. The affine matrices from a subgroup of $GL(n+1)$.</p>
<h2 id="1-11-The-Orthogonal-Group-O-n"><a href="#1-11-The-Orthogonal-Group-O-n" class="headerlink" title="1.11 The Orthogonal Group $O(n)$"></a>1.11 The Orthogonal Group $O(n)$</h2><p>A matrix $A\in M(n)$ is called <code>orthogonal</code> if it preserves the inner product, i.e.:<br>$$<br>&lt;Ax, Ay&gt; &#x3D; &lt;x, y&gt;, \quad \forall x, y \in \mathbb{R}^n<br>$$</p>
<p>The set of all orthogonal matrices forms the <code>orthogonal group</code> $O(n)$, which is a subgroup og $GL(n)$. For an orthogonal matrix $R$ we have:<br>$$<br>&lt;Rx, Ry&gt; &#x3D; x^TR^TRy&#x3D;x^Ty, \quad \forall x,y\in \mathbb{R}^n<br>$$</p>
<p>Therefore we must have $R^TR&#x3D;RR^T&#x3D;I$, in other words:<br>$$<br>O(n) &#x3D; {R\in GL(n) | R^TR&#x3D;I}<br>$$</p>
<p>The above identity shows that for any orthogonal matsix $R$, we have $det(R^TR)&#x3D;(det(R))^2&#x3D;det(I)&#x3D;1$, such that $det(R)\in {\pm 1}$. </p>
<p>The subgroup of $O(n)$ with $det(R)&#x3D;+1 $ is called the <code>special orthogonal group</code> $SO(n)$. $SO(n)&#x3D;O(n)\cap SL(n)$. In particular, $SO(3)$ is the group of all 3-dimensional rotation matrices.</p>
<h2 id="1-12-The-Euclidean-Group-E-n"><a href="#1-12-The-Euclidean-Group-E-n" class="headerlink" title="1.12 The Euclidean Group $E(n)$"></a>1.12 The Euclidean Group $E(n)$</h2><p>A Euclidean transformation $L$ from $\mathbb{R}^n$ to $\mathbb{R}^n$ is defined by an orthogonal matrix $R\in O(n)$ and a vector $T\in \mathbb{R}^n$:<br>$$<br>L: \mathbb{R}^n \rightarrow \mathbb{R}^n; \quad x \rightarrow Rx + T<br>$$</p>
<p>The set of all such transformations is called the <code>Euclidean group</code> $E(n)$. It is a subgroup of the affine group $A(n)$. Embedded by homogeneous coordinates, we get:<br>$$<br>E(n)&#x3D;{<br>    \left(<br>        \begin{matrix}<br>            R \quad &amp;T\\<br>            0\quad &amp;1<br>        \end{matrix}<br>        \right) |R\in O(n), T\in \mathbb{R}^n<br>    }.<br>$$</p>
<p>If $R\in SO(n) (i.e. det(R)&#x3D;1)$, then we have the <code>special Euclidean group</code> $SE(n)$. In particular, $SE(3)$ represents the <code>rigid-body motions</code> (dt: Starrkorpertransformationen) in $\mathbb{R}^3$.</p>
<p>In summary:<br>$$<br>SO(n) \subset O(n) \subset GL(n), \quad \<br>SE(n) \subset E(n) \subset A(n) \subset GL(n+1).<br>$$</p>
<h2 id="1-13-Range-Span-Null-Space-and-Kernel"><a href="#1-13-Range-Span-Null-Space-and-Kernel" class="headerlink" title="1.13 Range, Span, Null Space and Kernel"></a>1.13 Range, Span, Null Space and Kernel</h2><p>Let $A\in \mathbb{R}^{m\times n}$ be a matrix defining a linear map from $\mathbb{R}^n$ to $\mathbb{R}^m$. The <code>range</code> or <code>span</code> of $A$ (dt: Bild) is defined as the subspace of $\mathbb{R}^m$ which can be reached by $A$:<br>$$<br>range(A)&#x3D;{y\in \mathbb{R}^m | \exists  x\in \mathbb{R}^n: Ax&#x3D;y}.<br>$$</p>
<p>The range of a matrix $A$ is given by the span of its column vectors.</p>
<p>The <code>null space</code> or <code>kernel</code> of a matrix $A$ (dt: Kern) is given by the subset of vectors $x\in \mathbb{R}^n$ which are mapped to zero:<br>$$<br>null(A) &#x3D; ker(A) &#x3D; {x\in \mathbb{R}^n | Ax&#x3D;0}.<br>$$</p>
<p>The null space of a matrix $A$ is given by the vectors orthogonal to its row vectors. <code>MatLab: z=null(A)</code>.</p>
<p>The concepts of range and null space are useful when studying the <code>solution of linear equations</code>. The system $Ax&#x3D;b$ will have a solution $x\in \mathbb{R}^n$ if and only if $b\in range(A)$. Moreover, this solution will be unique only if $ker(A)&#x3D;0$. Indeed, if $x_s$ is a solution of $Ax&#x3D;b$ and $x_o \in ker(A)$, then $x_s+x_o$ is also a solution: $A(x_s + x_o)&#x3D;Ax_s + Ax_o &#x3D; b$.</p>
<h2 id="1-14-Rank-of-a-Matrix"><a href="#1-14-Rank-of-a-Matrix" class="headerlink" title="1.14 Rank of a Matrix"></a>1.14 Rank of a Matrix</h2><p>The <code>rank</code> of a matrix (dt. Rang) is the dimension of its range:<br>$$<br>rank(A) &#x3D; dim(range(A))<br>$$</p>
<p>The rank of a matrix $A\in \mathbb{R}^{m\times n}$ has the following properties:</p>
<ul>
<li>$rank(A) &#x3D; n-dim(ker(A))$</li>
<li>$0\leq rank(A) \leq min(m, n)$</li>
<li>$rank(a)$ is equal to the maximum number of linearly independent row (or column) vectors of $A.$</li>
<li>$rank(A)$ is the highest order of a nonzero minor of $A$, where a <code>minor of order k</code> is the determinant of a $k\times k$ submatrix of $A$.</li>
<li>Sylvester’s inequality: Let $B\in \mathbb{R}^{n\times k}$, then $AB\in \mathbb{R}^{m\times k}$ and $rank(A) + rank(B) - n \leq rank(AB) \leq min(rank(A), rank(B))$.</li>
<li>For any nonsingular matrices $C\in \mathbb{R}^{m\times m}$ and $D\in \mathbb{R}^{n\times n}$, we have : $rank(A)&#x3D;rank(CAD)$.</li>
</ul>
<h2 id="1-15-Eigenvalues-and-Eigenvectors"><a href="#1-15-Eigenvalues-and-Eigenvectors" class="headerlink" title="1.15 Eigenvalues and Eigenvectors"></a>1.15 Eigenvalues and Eigenvectors</h2><p>Let $A\in \mathbb{C}^{n\times n}$ be a complex matrix. A non-zero vector $v\in \mathbb{C}^n$ is called a <code>(right) eigenvector of A</code> if:<br>$$<br>Av &#x3D; \lambda v, \quad with \lambda \in \mathbb{C}.<br>$$<br>$\lambda$ is called an <code>eigenvalue of </code> $A$. Similarly $v$ is called a <code>left eigenvalue</code> of $A$, if $v^TA&#x3D;\lambda v^T$ for some $\lambda \in \mathbb{C}$. The <code>spectrum </code> $\sigma(A)$ of a matrix $A$ is the set of all its eigenvalues. <code>Matlab: [V, D] = eig(A);</code><br>where $D$ is a diagonal matrix containing the eigenvalues and $V$ is a matrix whose columns are the corresponding eigenvectors, such that $AV&#x3D;VD$.</p>
<h2 id="1-16-Properties-of-Eigenvalues-and-Eigenvectors"><a href="#1-16-Properties-of-Eigenvalues-and-Eigenvectors" class="headerlink" title="1.16 Properties of Eigenvalues and Eigenvectors"></a>1.16 Properties of Eigenvalues and Eigenvectors</h2><p>Let $A\in \mathbb{R}^{n\times n}$ be a square matrix. Then:</p>
<ul>
<li>If $Av&#x3D;\lambda v$ for some $\lambda \in \mathbb{R}$, then there also exists a left-eigenvector $\eta \in \mathbb{R}^n$: $\eta^TA &#x3D; \lambda \eta ^T$. Hence $\sigma (A)&#x3D;\sigma (A^T)$.</li>
<li>The eigenvectors of a matrix $A$ associated with different eigenvalues are linearly independent.</li>
<li>All eigenvalues $\sigma(A)$ are the roots of the characteristic polynomial equation $det(\lambda I-A)&#x3D;0$. Therefore $det(A)$ is equal to the product of all eigenvalues (some of which may appear multiple times).</li>
<li>If $B&#x3D;PAP^{-1}$ for some nonsingular matrix $P$, then $\sigma (B)&#x3D;\sigma(A)$.</li>
<li>If $\lambda \in \mathbb{C}$ is an eigenvalues, then its conjugate $\bar{\lambda}$ is also an eigenvalue. Thus $\sigma (A)&#x3D;\sigma(\bar{A})$ for real matrices $A$.</li>
</ul>
<h2 id="1-17-Symmetric-Matrices"><a href="#1-17-Symmetric-Matrices" class="headerlink" title="1.17 Symmetric Matrices"></a>1.17 Symmetric Matrices</h2><p>A matrix $S\in \mathbb{R}^{n\times n}$ is called <code>symmetric</code> if $S^T&#x3D;S$. A symmetric matrix $S$ is called <code>positive semi-definite (denoted by )</code> $S\geq 0$ or $S\succeq 0$. $S$ is called <code>positive definite (denoted by )</code> $S&gt;0$ or $S\succ 0$ if $x^TSx &gt;0 \ \forall x\neq 0$.</p>
<p>Let $S\in \mathbb{R}^{n\times n}$ be a real symmetric matrix. Then:</p>
<ul>
<li>All eigenvalues of $S$ are real, i.e. $\sigma (S) \subset \mathbb{R}$.</li>
<li>Eigenvectors $v_i$ and $v_j$ of $S$ corresponding to distinct eigenvalues $\lambda_i \neq \lambda_j$ are orthogonal.</li>
<li>There always exist $n$ orthogonal eogenvectors of $S$ which form a basis of $\mathbb{R}^n$. Let $V&#x3D;(v_1, v_2,…,v_n) \in O(n)$ be the orthogonal matrix of these diagonal matrix of eigenvalues. Then we have $S&#x3D;V\land V^T$.</li>
<li>$S$ is positive (semi-) definite, if all eigenvalues are positive (nonnegative).</li>
<li>Let $S$ be positive semi-definite and $\lambda_1, \lambda_n$ are the largest and smallest eigenvalues. Then $\lambda_1&#x3D;max_{|x|&#x3D;1}&lt;x, Sx&gt;$ and $\lambda_n &#x3D; min_{|x|&#x3D;1}&lt;x, Sx&gt;$.</li>
</ul>
<h2 id="1-18-Norms-of-Matrices"><a href="#1-18-Norms-of-Matrices" class="headerlink" title="1.18 Norms of Matrices"></a>1.18 Norms of Matrices</h2><p>There are many ways to define norms on the space of matrices $A \in \mathbb{R}^{n \times n}$. They can be defined based on norms on the domain or codomain spaces on which $A$ operates. In particular, the <code>induced 2-norm of a matrix</code> $A$ is defined as<br>$$<br>||A||<em>2 \equiv \max</em>{|x|_2&#x3D;1}|Ax|<em>2&#x3D;\max</em>{|x|_2&#x3D;1}\sqrt{&lt;x, A^TAx&gt;}.<br>$$</p>
<p>Alternatively, one can define the <code>Frobenius norm of</code> $A$ as:<br>$$<br>||A||<em>t \equiv \sqrt{\sum</em>{i, j}a_{ij}^2}&#x3D;\sqrt{trace(A^TA)}.<br>$$</p>
<p>Note that these norms are in general not the same. Since the matrix $A^TA$ is symmetric and pos, semi-definite, we can diagonalize it as: $A^TA&#x3D;Vdiag{\sigma_1^2, …,\sigma_n^2}V^T$ with $\sigma_1^2\geq \sigma_i^2 \geq 0$. This leads to:<br>$$<br>||A||_2&#x3D;\sigma_1, \quad and \ ||A||_i &#x3D; \sqrt{trace(A^TA)}&#x3D;\sqrt{\sigma_1^2 + …+\sigma_n^2}.<br>$$</p>
<h2 id="1-19-Skew-symmetric-Matrices"><a href="#1-19-Skew-symmetric-Matrices" class="headerlink" title="1.19 Skew-symmetric Matrices"></a>1.19 Skew-symmetric Matrices</h2><p>A matrix $A\in \mathbb{R}^{n\times n}$ is called <code>skew-symmetric</code> or <code>anti-symmetric</code> (dt. schiefsymmetrisch) if $A^T&#x3D;-A$.</p>
<p>If $A$ is a real skew-symmetric matrix, then:</p>
<ul>
<li>All eigenvalues of $A$ are either zero or purely imaginary, i.e. of the form $i\omega$ with $i^2&#x3D;-1, \omega \in \mathbb{R}$.</li>
<li>There exists an orthogonal matrix $V$ such that<br>  $$A &#x3D; V\Lambda V^T,$$<br>  where $\Lambda$ is a block-diagonal matrix $\Lambda&#x3D;diag{A_1, …, A_m,0, …,0}$, with real skew-symmetric matrices $A_i$ of the form:<br>  $$A_i&#x3D;\left(\begin{matrix} 0 \ &amp;a_i \\ -a_i\ &amp;0\end{matrix}\right) \in \mathbb{R}^{2\times 2}, \ i&#x3D;1,…,m.$$</li>
</ul>
<p>In particular, the rank of any skew-symmetric matrix is even.</p>
<h2 id="1-20-Example-of-Skew-symmetric-Matrices"><a href="#1-20-Example-of-Skew-symmetric-Matrices" class="headerlink" title="1.20 Example of Skew-symmetric Matrices"></a>1.20 Example of Skew-symmetric Matrices</h2><p>In Computer Vision, a common skew-symmetric matrix is given by <code>hat operator</code> of a vector $u\in \mathbb{R}^3$ is :<br>$$<br>\hat{u} &#x3D; \left(<br>    \begin{matrix}<br>    0 \ &amp;-u_3 \ &amp;u_2 \\<br>    u_3 \ &amp;0 \ &amp;-u_1\\<br>    -u_2 \ &amp;u_1 \ &amp;0<br>    \end{matrix}\right) \in \mathbb{R}^{3\times 3}.<br>$$</p>
<p>This is a linear operator from the space of vectors $\mathbb{R}^3$ to the space of skew symmetric matrices in $\mathbb{R}^{3\times 3}$. In particular, the matrix $\hat{u}$ has the property that<br>$$\hat{u}v&#x3D;u\times v,$$<br>where $\times$ denotes the standard vector cross product in $\mathbb{R}^3$. For $u\neq 0$, we have $rank(\hat{u})&#x3D;2$ and the null space of $\hat{u}$ is spanned by $u$, because $\hat{u}u&#x3D;u^T\hat{u}&#x3D;0$.</p>
<h2 id="1-21-The-Singular-Value-Decomposition-SVD"><a href="#1-21-The-Singular-Value-Decomposition-SVD" class="headerlink" title="1.21 The Singular Value Decomposition (SVD)"></a>1.21 The Singular Value Decomposition (SVD)</h2><p>In the above knowledge, we have studied many properties of matrices, such as rank, range, null space, and included norms of matrices. Many of these properties can be captured by the so-called <code>singular value decomposition (SVD)</code>.</p>
<p>SVD can be seen as a generalization of eigenvalues and eignvectors to non-square matrices. The computation of SVD is numerically well-conditioned. It is very useful for solving linear-algebraic problems such as matrix inversion, rank computation, linear least-squares estimation, projections, and fixed-rank approximations.</p>
<p>In practice, both singular value decomposition and eigenvalue decomposition are used quite extensively.</p>
<h2 id="1-22-Algebraic-Derivation-of-SVD"><a href="#1-22-Algebraic-Derivation-of-SVD" class="headerlink" title="1.22 Algebraic Derivation of SVD"></a>1.22 Algebraic Derivation of SVD</h2><p>Let $A\in \mathbb{R}^{m\times n}$ with $m\geq n$ be a matrix of $rank(A)&#x3D;p$. Then there exist</p>
<ul>
<li>$U\in \mathbb{R}^{m\times p}$ whose columns are orthonormal</li>
<li>$V\in \mathbb{R}^{n\times p}$ whose column are orthonormal, and </li>
<li>$\Sigma \in \mathbb{R}^{p\times p}$, $\Sigma &#x3D;diag{\sigma_1,…\sigma_p}$, with $\sigma_1 \geq … \geq \sigma_p$,<br>such that<br>$$<br>A &#x3D; U\Sigma V^T<br>$$</li>
</ul>
<p>Note that this <code>generalizes the eigenvalue decomposition</code>. While the latter decomposition symmetric square matrix $A$ with an orthogonal transformation $V$ as:<br>$$<br>A &#x3D;V\Lambda V^T, \ with V\in O(n), \ \Lambda&#x3D;diag{\lambda_1, …, \lambda_n},<br>$$</p>
<p>SVD allows to decompose an arbitrary (non-square) matrix $A$ of rank $p$ with two transformations $U$ and $V$ with orthonormal columns as shown above. Nevertheless, we will see that SVD is based on the eigenvalue decomposiiion of symmetric square matrices.</p>
<h2 id="1-23-Proof-of-SVD-Decomposition-1"><a href="#1-23-Proof-of-SVD-Decomposition-1" class="headerlink" title="1.23 Proof of SVD Decomposition 1"></a>1.23 Proof of SVD Decomposition 1</h2><p>Given a matrix $A\in \mathbb{R}^{m\times n}$ with $m\geq n$ and $rank(A)&#x3D;p$, the matrix<br>$$A^TA\in \mathbb{R}^{n\times n}$$<br>is symmetric and positive semi-definite. Therefore it can be decomposed with non-negative eigenvalues $\sigma_1^2\geq …\geq \sigma_n^2\geq 0$ with orthonormal eigenvalues $v_1,…,v_n$. The $\sigma_i$ are called <code>singular values</code>. Since<br>$$<br>ker(A^TA)&#x3D;ker(A) \ and \ range(A^TA) &#x3D; range(A^T),<br>$$<br>we have $span{v_1,…,v_p}&#x3D;range(A^T) and \ span{v_{p+1},…,v_n}&#x3D;ker(A)$. Let<br>$$<br>u_i&#x3D;\frac{1}{\sigma_i}Av_i \Leftrightarrow Av_i &#x3D; \sigma_i u_i, \ i&#x3D;1,…,p<br>$$<br>then the $u_i\in \mathbb{R}^m$ are orthonormal:<br>$$<br>&lt;u_i, u_j&gt;&#x3D;\frac{1}{\sigma_i \sigma_j}&lt;Av_i, Av_j&gt;&#x3D;\frac{1}{\sigma_i \sigma_j}&lt;v_i, A^TAv_j&gt;&#x3D;\delta_{ij},<br>$$<br>where<br>$$<br>\delta_{ij} &#x3D; \begin{cases}<br>             1, &amp;  i&#x3D;j\\<br>             0, &amp;i\neq j<br>             \end{cases}<br>$$</p>
<h2 id="1-23-Proof-of-SVD-Decomposition-2"><a href="#1-23-Proof-of-SVD-Decomposition-2" class="headerlink" title="1.23 Proof of SVD Decomposition 2"></a>1.23 Proof of SVD Decomposition 2</h2><p>Complete ${u_i}<em>{i&#x3D;1}^p$ to a basis ${u_i}</em>{i&#x3D;1}^m$. Since $Av_i&#x3D;\sigma_i u_i$, we have<br>$$<br>A(v_1, …, v_n)&#x3D;(u_1, …, u_m)\left(\begin{matrix}<br>    &amp;\sigma_1  &amp;0 &amp;0  &amp;\cdots  &amp;0 \\<br>    &amp;0 \ &amp;\ddots &amp;0 &amp;\vdots &amp;0 \\<br>    &amp;0 &amp;\cdots &amp;\sigma_p &amp;\vdots &amp;0 \\<br>    &amp;\vdots &amp;\cdots &amp;\cdots &amp;\vdots &amp;0 \\<br>    &amp;0 &amp;\cdots &amp;\cdots &amp;0 &amp;0<br>\end{matrix}\right),<br>$$<br>which is of the form $A\tilde{V}&#x3D;\tilde{U}\tilde{\Sigma}$, thus<br>$$<br>A &#x3D; \tilde{U}\tilde{\Sigma}\tilde{V}^T.<br>$$</p>
<p>Now simply delete all columns of $\tilde{U}$ and the rows of $\tilde{V}^T$ which are multiplied by zero singular values and we obtain the form $A&#x3D;U\Sigma V^T$, with $U\in \mathbb{R}^{m\times p}$ and $V\in \mathbb{R}^{n\times p}$.<br>In Matlab, <code>[U, S, V]=svd(A)</code>.</p>
<h2 id="1-24-A-Geomtric-Interpretation-of-SVD"><a href="#1-24-A-Geomtric-Interpretation-of-SVD" class="headerlink" title="1.24 A Geomtric Interpretation of SVD"></a>1.24 A Geomtric Interpretation of SVD</h2><p>For $A\in \mathbb{R}^{n\times n}$, the singular value decomposition $A&#x3D;U\Sigma V^T$ is sunch that the columns $U&#x3D;(u_1, …, u_n)$, and $V &#x3D; (v_1,…,v_n)$ form orthogonal bases of $\hat{n}$. If a point $x\in \mathbb{R}^n$ is mapped to a point $y\in \mathbb{R}^n$ by the transformation $A$, then the coordinates of $y$ in basis $U$ are related to the coordinates of $x$ in basis $V$ by the diagonal matrix $\Sigma:$ each coordinate is merely scaled by the corresponding singular value:<br>$$<br>y&#x3D;Ax &#x3D; U\Sigma V^T x \Leftrightarrow U^T y &#x3D; \Sigma V^T x.<br>$$</p>
<p><code>The matrix </code>$A$ <code>maps</code> the unit sphere into an ellipsoid with semi-axes $\sigma <em>i u_i$.<br>To see this, we call $\alpha \equiv V^T x$ the coefficients of the point $x$ in the basis $V$ and those of $y$ in basis $U$ shall be called $\beta \equiv U^Ty$. All points of the circle fulfill $|x|^2_2\sum</em>{i}\alpha ^2_i &#x3D; 1$. The above statement says that $\beta _i &#x3D; \sigma_i \alpha_i$. Thus for the points on the sphere we have:<br>$$<br>\sum_i \alpha_i^2 &#x3D; \sum_i \beta^2_i &#x2F; \sigma_i ^2 &#x3D; 1,<br>$$<br>which states that the transformed points lie on an ellipsoid oriented along the axes of the basis $U$.</p>
<h2 id="1-25-The-Generalized-Moore-Penrose-Inverse"><a href="#1-25-The-Generalized-Moore-Penrose-Inverse" class="headerlink" title="1.25 The Generalized (Moore Penrose) Inverse"></a>1.25 The Generalized (Moore Penrose) Inverse</h2><p>For certain quadratic matrices one can  define an inverse matrix, if $det(A)\neq 0 $. The set of all invertible matrices forms the group $GL(n)$. One can also define a (generalized) inverse (also called pseudo inverse) for an arbirary (non-quadratic) matrix $A\in \mathbb{R}^{m\times n}$. If its SVD is $A&#x3D;U\Sigma V^T$, the pseudo inverse is deined as:<br>$$<br>A^{\dagger} &#x3D; V\Sigma ^{\dagger} U^{T}, \ where \ \Sigma{\dagger}&#x3D;\left(<br>    \begin{aligned} &amp;\Sigma_1^{-1} &amp;0 \\<br>                    &amp;0 &amp;0\end{aligned}\right)_{n\times m}<br>$$<br>where $\Sigma_1$ is the diagonal matrix of non-zero singular values. In Matlab: <code>X=pinv(A)</code>. In particular, the pseudo inverse can be employed in a singular fashion as the inverse of quadratic invertible matrices:<br>$$<br>AA^{\dagger}A&#x3D;A, \quad A^{\dagger}AA^{\dagger}&#x3D;A{\dagger}.<br>$$</p>
<p>The linear system $Ax&#x3D;b$ with $A\in \mathbb{R}^{m\times n}$ of rank $r\leq \min(m,n)$ can have multiple por no solutions. $x_{min}&#x3D;A^{\dagger}b$ is among all minimizers of $|Ax-b|^2$ the one with the smallest norm $|x|$.</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">KMnO4</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://wastoon.github.io/2022/02/21/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95%EF%BC%88%E4%B8%80%EF%BC%89/">https://wastoon.github.io/2022/02/21/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95%EF%BC%88%E4%B8%80%EF%BC%89/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://wastoon.github.io" target="_blank">KMnO4的行云小扎</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a><a class="post-meta__tags" href="/tags/SFM/">SFM</a></div><div class="post_share"><div class="social-share" data-image="/img/MVG-1-cover.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button button--animated"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.png" target="_blank"><img class="post-qr-code-img" src="/img/wechat.png" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.png" target="_blank"><img class="post-qr-code-img" src="/img/alipay.png" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/02/23/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95%EF%BC%88%E4%BA%8C%EF%BC%89/"><img class="prev-cover" src="/img/MVG-2-cover.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">多视图几何（二）</div></div></a></div><div class="next-post pull-right"><a href="/2021/11/21/Transformer%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"><img class="next-cover" src="/img/transformer.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Transformer的前世今生</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/03/16/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95%EF%BC%88%E4%B8%83%EF%BC%89/" title="多视图几何（七）"><img class="cover" src="/img/MVG-7-cover.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-16</div><div class="title">多视图几何（七）</div></div></a></div><div><a href="/2022/02/23/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95%EF%BC%88%E4%B8%89%EF%BC%89/" title="多视图几何（三）"><img class="cover" src="/img/MVG-3-cover.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-23</div><div class="title">多视图几何（三）</div></div></a></div><div><a href="/2022/02/23/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95%EF%BC%88%E4%BA%8C%EF%BC%89/" title="多视图几何（二）"><img class="cover" src="/img/MVG-2-cover.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-23</div><div class="title">多视图几何（二）</div></div></a></div><div><a href="/2022/02/28/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95%EF%BC%88%E4%BA%94%EF%BC%89/" title="多视图几何（五）"><img class="cover" src="/img/MVG-5-cover.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-28</div><div class="title">多视图几何（五）</div></div></a></div><div><a href="/2022/02/28/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95%EF%BC%88%E5%9B%9B%EF%BC%89/" title="多视图几何（四）"><img class="cover" src="/img/MVG-4-cover.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-28</div><div class="title">多视图几何（四）</div></div></a></div><div><a href="/2022/03/09/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95%EF%BC%88%E5%85%AD%EF%BC%89/" title="多视图几何（六）"><img class="cover" src="/img/MVG-5-cover.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-09</div><div class="title">多视图几何（六）</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">KMnO4</div><div class="author-info__description">西安交通大学硕士（CV，3D人体姿态估计，动作生成）</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">10</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">8</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Wastoon"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Wastoon" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="/mengrongye@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">Everything is the meaning of life.<div class="twopeople"><div class="twopeople"><div class="container"style="height:200px;"><canvas class="illo"width="800"height="800"style="max-width: 200px; max-height: 200px; touch-action: none; width: 640px; height: 640px;"></canvas></div><script src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/twopeople1.js"></script><script src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/zdog.dist.js"></script><script id="rendered-js"src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/twopeople.js"></script><style>.twopeople{margin:0;align-items:center;justify-content:center;text-align:center}canvas{display:block;margin:0 auto;cursor:move}</style></div></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-1-Mathematical-Background-Linear-Algebra"><span class="toc-number">1.</span> <span class="toc-text">Chapter 1 Mathematical Background Linear Algebra</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-5-Canocial-and-Induces-Inner-Product"><span class="toc-number">1.1.</span> <span class="toc-text">1.5 Canocial and Induces Inner Product</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-6-Kronecker-Product-and-Stack-of-a-Matrix"><span class="toc-number">1.2.</span> <span class="toc-text">1.6 Kronecker Product and Stack of a Matrix</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-7-Linear-Transformation-and-Matrices"><span class="toc-number">1.3.</span> <span class="toc-text">1.7 Linear Transformation and Matrices</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-8-The-linear-Groups-GL-n-and-SL-n"><span class="toc-number">1.4.</span> <span class="toc-text">1.8 The linear Groups $GL(n)$ and $SL(n)$</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-9-Matrix-Representation-of-Groups"><span class="toc-number">1.5.</span> <span class="toc-text">1.9 Matrix Representation of Groups</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-10-The-Affine-Group-A-n"><span class="toc-number">1.6.</span> <span class="toc-text">1.10 The Affine Group $A(n)$</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-11-The-Orthogonal-Group-O-n"><span class="toc-number">1.7.</span> <span class="toc-text">1.11 The Orthogonal Group $O(n)$</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-12-The-Euclidean-Group-E-n"><span class="toc-number">1.8.</span> <span class="toc-text">1.12 The Euclidean Group $E(n)$</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-13-Range-Span-Null-Space-and-Kernel"><span class="toc-number">1.9.</span> <span class="toc-text">1.13 Range, Span, Null Space and Kernel</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-14-Rank-of-a-Matrix"><span class="toc-number">1.10.</span> <span class="toc-text">1.14 Rank of a Matrix</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-15-Eigenvalues-and-Eigenvectors"><span class="toc-number">1.11.</span> <span class="toc-text">1.15 Eigenvalues and Eigenvectors</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-16-Properties-of-Eigenvalues-and-Eigenvectors"><span class="toc-number">1.12.</span> <span class="toc-text">1.16 Properties of Eigenvalues and Eigenvectors</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-17-Symmetric-Matrices"><span class="toc-number">1.13.</span> <span class="toc-text">1.17 Symmetric Matrices</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-18-Norms-of-Matrices"><span class="toc-number">1.14.</span> <span class="toc-text">1.18 Norms of Matrices</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-19-Skew-symmetric-Matrices"><span class="toc-number">1.15.</span> <span class="toc-text">1.19 Skew-symmetric Matrices</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-20-Example-of-Skew-symmetric-Matrices"><span class="toc-number">1.16.</span> <span class="toc-text">1.20 Example of Skew-symmetric Matrices</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-21-The-Singular-Value-Decomposition-SVD"><span class="toc-number">1.17.</span> <span class="toc-text">1.21 The Singular Value Decomposition (SVD)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-22-Algebraic-Derivation-of-SVD"><span class="toc-number">1.18.</span> <span class="toc-text">1.22 Algebraic Derivation of SVD</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-23-Proof-of-SVD-Decomposition-1"><span class="toc-number">1.19.</span> <span class="toc-text">1.23 Proof of SVD Decomposition 1</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-23-Proof-of-SVD-Decomposition-2"><span class="toc-number">1.20.</span> <span class="toc-text">1.23 Proof of SVD Decomposition 2</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-24-A-Geomtric-Interpretation-of-SVD"><span class="toc-number">1.21.</span> <span class="toc-text">1.24 A Geomtric Interpretation of SVD</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-25-The-Generalized-Moore-Penrose-Inverse"><span class="toc-number">1.22.</span> <span class="toc-text">1.25 The Generalized (Moore Penrose) Inverse</span></a></li></ol></li></ol></div></div><div class="card-widget card-weibo"><div class="card-content"><div class="item-headline"><i class="fab fa-weibo"></i><span>微博热搜</span></div><div id="weibo-container" style="width: 100%; height: 150px;font-size: 95%;"></div></div></div><script defer="defer" data-pjax="data-pjax" src="/js/card_weibo.js"></script><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/03/16/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95%EF%BC%88%E4%B8%83%EF%BC%89/" title="多视图几何（七）"><img src="/img/MVG-7-cover.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="多视图几何（七）"/></a><div class="content"><a class="title" href="/2022/03/16/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95%EF%BC%88%E4%B8%83%EF%BC%89/" title="多视图几何（七）">多视图几何（七）</a><time datetime="2022-03-16T11:44:07.000Z" title="发表于 2022-03-16 19:44:07">2022-03-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/03/09/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95%EF%BC%88%E5%85%AD%EF%BC%89/" title="多视图几何（六）"><img src="/img/MVG-5-cover.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="多视图几何（六）"/></a><div class="content"><a class="title" href="/2022/03/09/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95%EF%BC%88%E5%85%AD%EF%BC%89/" title="多视图几何（六）">多视图几何（六）</a><time datetime="2022-03-09T08:15:24.000Z" title="发表于 2022-03-09 16:15:24">2022-03-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/02/28/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95%EF%BC%88%E4%BA%94%EF%BC%89/" title="多视图几何（五）"><img src="/img/MVG-5-cover.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="多视图几何（五）"/></a><div class="content"><a class="title" href="/2022/02/28/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95%EF%BC%88%E4%BA%94%EF%BC%89/" title="多视图几何（五）">多视图几何（五）</a><time datetime="2022-02-28T07:02:52.000Z" title="发表于 2022-02-28 15:02:52">2022-02-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/02/28/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95%EF%BC%88%E5%9B%9B%EF%BC%89/" title="多视图几何（四）"><img src="/img/MVG-4-cover.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="多视图几何（四）"/></a><div class="content"><a class="title" href="/2022/02/28/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95%EF%BC%88%E5%9B%9B%EF%BC%89/" title="多视图几何（四）">多视图几何（四）</a><time datetime="2022-02-28T06:43:44.000Z" title="发表于 2022-02-28 14:43:44">2022-02-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/02/23/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95%EF%BC%88%E4%B8%89%EF%BC%89/" title="多视图几何（三）"><img src="/img/MVG-3-cover.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="多视图几何（三）"/></a><div class="content"><a class="title" href="/2022/02/23/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95%EF%BC%88%E4%B8%89%EF%BC%89/" title="多视图几何（三）">多视图几何（三）</a><time datetime="2022-02-23T11:44:57.000Z" title="发表于 2022-02-23 19:44:57">2022-02-23</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/img/MVG-1-cover.png')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By KMnO4</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: '60cf579829afb2b2cdf9',
      clientSecret: '991dfac32f5e2bd0470bd4b8f5b8a2ef54e9b164',
      repo: 'Wastoon.github.io',
      owner: 'Wastoon',
      admin: ['Wastoon'],
      id: '0dcbe23e4ad0c4a24ea995a66b93fd25',
      language: 'zh-CN',
      perPage: 10,
      distractionFreeMode: false,
      pagerDirection: 'last',
      createIssueManually: true,
      updateCountCallback: commentCount
    },false))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !true) {
  if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="true"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-show-text.min.js" data-mobile="false" data-text="I,Miss,You" data-fontsize="15px" data-random="false" async="async"></script><script>((window.gitter = {}).chat = {}).options = {
  disableDefaultChat: true,
};
document.addEventListener('gitter-sidecar-ready', (e) => {
  const GitterChat = e.detail.Chat
  let chat

  function initGitter () {
    chat = new GitterChat({
      room: 'OMGsitetalk/community',
      activationElement: '#chat_btn'
    });
  }

  initGitter()

  if (false) {
    document.addEventListener('pjax:complete', () => {
      chat.destroy()
      initGitter()
    })
  }

})</script><script src="https://sidecar.gitter.im/dist/sidecar.v1.js" async="async" defer="defer"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_clock_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/tzy13755126023/BLOG_SOURCE/theme_f/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_injector_config();
  }
  </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax src="https://cdn.jsdelivr.net/npm/hexo-butterfly-clock/lib/clock.min.js"></script><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><script data-pjax src="https://cdn.jsdelivr.net/npm/hexo-filter-gitcalendar/lib/gitcalendar.js"></script><script data-pjax>
                        function gitcalendar_injector_config(){
                          var parent_div_git = document.getElementById('recent-posts');
                          var item_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><style>#git_container{min-height: 280px}@media screen and (max-width:650px) {#git_container{min-height: 0px}}</style><div id="git_loading" style="width:10%;height:100%;margin:0 auto;display: block;"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animatetransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animatetransform></path></svg><style>#git_container{display: none;}</style></div><div id="git_container"></div></div>';
                          parent_div_git.insertAdjacentHTML("afterbegin",item_html)
                          console.log('已挂载gitcalendar')
                          }

                        if( document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
                            gitcalendar_injector_config()
                            GitCalendarInit("https://gitcalendar.akilar.top/api?Wastoon",['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'],'Wastoon')
                        }
                      </script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>